{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the description in:\n",
    "    \n",
    "https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/\n",
    "\n",
    "Paper:\n",
    "\n",
    "https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf\n",
    "\n",
    "Paper Author homepage:\n",
    "\n",
    "https://kpzhang93.github.io/MTCNN_face_detection_alignment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.0\n"
     ]
    }
   ],
   "source": [
    "# confirm mtcnn was installed correctly\n",
    "import mtcnn\n",
    "# print version\n",
    "print(mtcnn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum box size for detecting a face can be specified via the ‘min_face_size‘ argument, which defaults to 20 pixels. The constructor also provides a ‘scale_factor‘ argument to specify the scale factor for the input image, which defaults to 0.709."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image from file\n",
    "#filename = '../Bilder/african-presidents.jpg'\n",
    "#filename = '../Bilder/HochschuleFurtwangen.JPG'\n",
    "\n",
    "filename = 'mannschaft.jpg'#png mag er nicht, da die Werte im Bereich 0-1 liegen\n",
    "my_min_face_size=20#original param\n",
    "my_scale_factor= 0.709#original param\n",
    "#my_min_face_size=10# best param for Hochschule Furtwangen\n",
    "#my_scale_factor= 0.79#best param for Hochschule Furtwangen\n",
    "#my_min_face_size=10# best param for mannschaft\n",
    "#my_scale_factor= 0.39#best param for mannschaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection with mtcnn on a photograph\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from mtcnn import MTCNN\n",
    " \n",
    "# draw an image with detected objects\n",
    "def draw_image_with_boxes(filename, result_list):\n",
    "    # load the image\n",
    "    data = pyplot.imread(filename)\n",
    "    # plot the image\n",
    "    pyplot.figure(figsize = (20,10))\n",
    "    pyplot.imshow(data, aspect='auto')\n",
    "    # get the context for drawing boxes\n",
    "    ax = pyplot.gca()\n",
    "    # plot each box\n",
    "    for result in result_list:\n",
    "        # get coordinates\n",
    "        x, y, width, height = result['box']\n",
    "        # create the shape\n",
    "        rect = Rectangle((x, y), width, height, fill=False, color='green', lw = 3)\n",
    "        # draw the box\n",
    "        ax.add_patch(rect)\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    #pyplot.savefig('detected_mannschaft.png',dpi=300)\n",
    " \n",
    "# load image from file\n",
    "pixels = pyplot.imread(filename)\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN(min_face_size=my_min_face_size, scale_factor= my_scale_factor, steps_threshold = [0.6,0.7,0.7])\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "# display faces on the original image\n",
    "draw_image_with_boxes(filename, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\basti\\Documents\\Git-Repos\\ML-for-CV-INM1\\Tasks\\Practical_03\\DeepLearning-Face-detection.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/basti/Documents/Git-Repos/ML-for-CV-INM1/Tasks/Practical_03/DeepLearning-Face-detection.ipynb#ch0000006?line=0'>1</a>\u001b[0m faces\n",
      "\u001b[1;31mNameError\u001b[0m: name 'faces' is not defined"
     ]
    }
   ],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413, 1000, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "faces = detector.detect_faces(255*pixels[:,:500,:])\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.max(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
